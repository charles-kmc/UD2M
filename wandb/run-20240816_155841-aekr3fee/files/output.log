Epoch ==== >> 0
Epoch ==== >> 0	|	 batch ==== >> 0
Started ...
2024-08-16 15:58:45,342 - INFO - loss:  0.07442310452461243
2024-08-16 15:58:45,343 - INFO - loss_q3: 0.0687117800116539
2024-08-16 15:58:45,343 - INFO - loss_q1: 0.07871949672698975
2024-08-16 15:58:45,343 - INFO - loss_q0: 0.09830150008201599
2024-08-16 15:58:45,343 - INFO - loss_q3: 0.06963977217674255
2024-08-16 15:58:45,344 - INFO - loss_q2: 0.06998252868652344
2024-08-16 15:58:45,344 - INFO - loss_q3: 0.06739434599876404
2024-08-16 15:58:45,344 - INFO - loss_q2: 0.07067085802555084
2024-08-16 15:58:45,344 - INFO - loss_q1: 0.0719645619392395
2024-08-16 15:58:46,000 - INFO - grad_norm: 0.08279115575678328
2024-08-16 15:58:46,001 - INFO - param_norm: 185.82826280727775
--- Logging error ---
Traceback (most recent call last):
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 93, in <module>
    main()
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 90, in main
    trainer_accelerate.run_training_loop(num_epochs)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 215, in run_training_loop
    self.run_epoch(batch_data, batch_sol_Tk, batch_y, blur_kernel_op, epoch)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 270, in run_epoch
    self.log_epoch(epoch)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 341, in log_epoch
    self.logger.info("epoch: ", epoch + self.resume_epoch)
Message: 'epoch: '
Arguments: (0,)
--- Logging error ---
Traceback (most recent call last):
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 93, in <module>
    main()
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 90, in main
    trainer_accelerate.run_training_loop(num_epochs)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 215, in run_training_loop
    self.run_epoch(batch_data, batch_sol_Tk, batch_y, blur_kernel_op, epoch)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 270, in run_epoch
    self.log_epoch(epoch)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 341, in log_epoch
    self.logger.info("epoch: ", epoch + self.resume_epoch)
Message: 'epoch: '
Arguments: (0,)
--- Logging error ---
Traceback (most recent call last):
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 93, in <module>
    main()
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 90, in main
    trainer_accelerate.run_training_loop(num_epochs)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 215, in run_training_loop
    self.run_epoch(batch_data, batch_sol_Tk, batch_y, blur_kernel_op, epoch)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 270, in run_epoch
    self.log_epoch(epoch)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 342, in log_epoch
    self.logger.info("batch: ", self.ii)
Message: 'batch: '
Arguments: (0,)
--- Logging error ---
Traceback (most recent call last):
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 93, in <module>
    main()
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 90, in main
    trainer_accelerate.run_training_loop(num_epochs)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 215, in run_training_loop
    self.run_epoch(batch_data, batch_sol_Tk, batch_y, blur_kernel_op, epoch)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 270, in run_epoch
    self.log_epoch(epoch)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 342, in log_epoch
    self.logger.info("batch: ", self.ii)
Message: 'batch: '
Arguments: (0,)
--- Logging error ---
Traceback (most recent call last):
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 93, in <module>
    main()
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 90, in main
    trainer_accelerate.run_training_loop(num_epochs)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 215, in run_training_loop
    self.run_epoch(batch_data, batch_sol_Tk, batch_y, blur_kernel_op, epoch)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 270, in run_epoch
    self.log_epoch(epoch)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 343, in log_epoch
    self.logger.info("samples: ", (epoch + self.resume_epoch + 1) * self.global_batch)
Message: 'samples: '
Arguments: (8,)
--- Logging error ---
Traceback (most recent call last):
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/.conda/envs/dmog_env39/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 93, in <module>
    main()
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 90, in main
    trainer_accelerate.run_training_loop(num_epochs)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 215, in run_training_loop
    self.run_epoch(batch_data, batch_sol_Tk, batch_y, blur_kernel_op, epoch)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 270, in run_epoch
    self.log_epoch(epoch)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 343, in log_epoch
    self.logger.info("samples: ", (epoch + self.resume_epoch + 1) * self.global_batch)
Message: 'samples: '
Arguments: (8,)
Traceback (most recent call last):
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 93, in <module>
    main()
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 90, in main
    trainer_accelerate.run_training_loop(num_epochs)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 223, in run_training_loop
    self.save(epoch)
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 363, in save
    save_checkpoint(0, self.model.parameters())
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 350, in save_checkpoint
    state_dict = params_to_state_dict(un_wrapped_model, params)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 443, in params_to_state_dict
    state_dict[name] = params[i]
                       ~~~~~~^^^
TypeError: 'generator' object is not subscriptable
[rank0]: Traceback (most recent call last):
[rank0]:   File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 93, in <module>
[rank0]:     main()
[rank0]:   File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/main_training_accelerate.py", line 90, in main
[rank0]:     trainer_accelerate.run_training_loop(num_epochs)
[rank0]:   File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 223, in run_training_loop
[rank0]:     self.save(epoch)
[rank0]:   File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 363, in save
[rank0]:     save_checkpoint(0, self.model.parameters())
[rank0]:   File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 350, in save_checkpoint
[rank0]:     state_dict = params_to_state_dict(un_wrapped_model, params)
[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/users/cmk2000/cmk2000/Deep learning models/LLMs/Conditional-Diffusion-Models-for-IVP/models/trainer_accelerate.py", line 443, in params_to_state_dict
[rank0]:     state_dict[name] = params[i]
[rank0]:                        ~~~~~~^^^
[rank0]: TypeError: 'generator' object is not subscriptable