{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmk2000/.conda/envs/horus_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import os\n",
    "dir = \"/home/cmk2000/Documents/Years 3/Python codes/Codes/LLMs/Conditional-Diffusion-Model-for-IVP\"\n",
    "os.chdir(dir)\n",
    "from models.model import FineTuningDiffusionModel\n",
    "\n",
    "\n",
    "from guided_diffusion import dist_util\n",
    "from guided_diffusion.script_util import (\n",
    "    NUM_CLASSES,\n",
    "    model_and_diffusion_defaults,\n",
    "    create_model_and_diffusion,\n",
    "    args_to_dict,\n",
    ")\n",
    "\n",
    "from utils import utils_model\n",
    "\n",
    "import datetime\n",
    "\n",
    "from guided_diffusion import dist_util\n",
    "from guided_diffusion.script_util import (\n",
    "    NUM_CLASSES,\n",
    "    model_and_diffusion_defaults,\n",
    "    create_model_and_diffusion,\n",
    "    args_to_dict,\n",
    ")\n",
    "\n",
    "\n",
    "from guided_diffusion.unet import *\n",
    "    \n",
    "from utils_lora.lora_parametrisation import LoRa_model,make_copy_model\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_parameters(model):\n",
    "    n_frozen = 0\n",
    "    n_lora = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"lora_\" not in name:\n",
    "            n_frozen += param.numel()\n",
    "        else:\n",
    "            n_lora += param.numel()\n",
    "    return n_frozen, n_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diffusion_ffhq_10m\n",
      "Number of Layers frozen: 362\n",
      "Total trainable parameters of the model: 93563910 (non-LoRa) vs 24576 (LoRa) Ratio: 0.03% of the original model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((93563910, 0), (93563910, 24576))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# Preparation\n",
    "# ----------------------------------------\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%d%B%Y\")\n",
    "\n",
    "device                  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "noise_level_img         = 12.75/255.0           # set AWGN noise level for LR image, default: 0\n",
    "noise_level_model       = noise_level_img       # set noise level of model, default: 0\n",
    "model_name              = 'diffusion_ffhq_10m' #'diffusion_ffhq_10m'  # diffusion_ffhq_10m, 256x256_diffusion_uncond; set diffusino model\n",
    "testset_name            = 'demo_test'            # set testing set,  'imagenet_val' | 'ffhq_val'\n",
    "num_train_timesteps     = 1000\n",
    "iter_num                = 1000              # set number of iterations\n",
    "iter_num_U              = 1                 # set number of inner iterations, default: 1\n",
    "skip                    = num_train_timesteps//iter_num     # skip interval\n",
    "\n",
    "\n",
    "log_process             = False\n",
    "ddim_sample             = False             # sampling method\n",
    "model_output_type       = 'pred_xstart'     # model output type: pred_x_prev; pred_xstart; epsilon; score\n",
    "generate_mode           = 'DiffPIR'         # DiffPIR; DPS; vanilla\n",
    "skip_type               = 'quad'            # uniform, quad\n",
    "eta                     = 0.0               # eta for ddim sampling\n",
    "zeta                    = 0.1  \n",
    "guidance_scale          = 1.0   \n",
    "\n",
    "calc_LPIPS              = True\n",
    "use_DIY_kernel          = True\n",
    "blur_mode               = 'Gaussian'          # Gaussian; motion      \n",
    "kernel_size             = 9\n",
    "kernel_std              = 3.0 if blur_mode == 'Gaussian' else 0.5\n",
    "\n",
    "if blur_mode=='Gaussian':\n",
    "    kernel_true_param   = .4\n",
    "else:\n",
    "    raise Exception(\"Hol' up, only Gaussian bois allowed here.\")\n",
    "\n",
    "\n",
    "\n",
    "sf                      = 1\n",
    "task_current            = 'deblur'          \n",
    "n_channels              = 3                 # fixed\n",
    "cwd                     = ''  \n",
    "model_zoo               = os.path.join(cwd, '/home/cmk2000/Documents/Years 2/Python codes and results/Python codes/Codes/pretrained_models/model_zoo')    # fixed\n",
    "testsets                = os.path.join(cwd, 'testsets')     # fixed\n",
    "model_path              = os.path.join(model_zoo, model_name+'.pt')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# noise schedule \n",
    "beta_start              = 0.1 / 1000\n",
    "beta_end                = 20 / 1000\n",
    "betas                   = np.linspace(beta_start, beta_end, num_train_timesteps, dtype=np.float32)\n",
    "betas                   = torch.from_numpy(betas).to(device)\n",
    "alphas                  = 1.0 - betas\n",
    "alphas_cumprod          = np.cumprod(alphas.cpu(), axis=0)\n",
    "sqrt_alphas_cumprod     = torch.sqrt(alphas_cumprod)\n",
    "sqrt_1m_alphas_cumprod  = torch.sqrt(1. - alphas_cumprod)\n",
    "reduced_alpha_cumprod   = torch.div(sqrt_1m_alphas_cumprod, sqrt_alphas_cumprod)        # equivalent noise sigma on image\n",
    "\n",
    "noise_model_t           = utils_model.find_nearest(reduced_alpha_cumprod, 2 * noise_level_model)\n",
    "noise_model_t           = 0\n",
    "\n",
    "noise_inti_img          = 50 / 255\n",
    "t_start                 = utils_model.find_nearest(reduced_alpha_cumprod, 2 * noise_inti_img) # start timestep of the diffusion process\n",
    "t_start                 = num_train_timesteps - 1              \n",
    "\n",
    "# ----------------------------------------\n",
    "# L_path, E_path, H_path\n",
    "# ----------------------------------------\n",
    "\n",
    "L_path = os.path.join(testsets, testset_name) # L_path, for Low-quality images\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# load model\n",
    "# ----------------------------------------\n",
    "print(model_name)\n",
    "model_config = dict(\n",
    "        model_path=model_path,\n",
    "        num_channels=128,\n",
    "        num_res_blocks=1,\n",
    "        attention_resolutions=\"16\",\n",
    "    ) if model_name == 'diffusion_ffhq_10m' \\\n",
    "    else dict(\n",
    "        model_path=model_path,\n",
    "        num_channels=256,\n",
    "        num_res_blocks=2,\n",
    "        attention_resolutions=\"8,16,32\",\n",
    "    )\n",
    "    \n",
    "args = utils_model.create_argparser(model_config).parse_args([])\n",
    "model, diffusion = create_model_and_diffusion(\n",
    "    **args_to_dict(args, model_and_diffusion_defaults().keys()))\n",
    "model.load_state_dict(\n",
    "    dist_util.load_state_dict(args.model_path, map_location=\"cpu\")\n",
    ")\n",
    "model.eval()\n",
    "for _k, v in model.named_parameters():\n",
    "    v.requires_grad = False\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "model_copy = make_copy_model(model)\n",
    "lora_model = LoRa_model(model_copy, input_block_layer_lora = [9, 9], middle_block_layer_lora = [1], output_block_layer_lora = [2, 3])\n",
    "\n",
    "total_parameters(model), total_parameters(lora_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (10): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (11): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): AttentionBlock(\n",
       "      (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "      (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "      (attention): QKVAttentionLegacy()\n",
       "      (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Upsample()\n",
       "        (x_upd): Upsample()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Upsample()\n",
       "        (x_upd): Upsample()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Upsample()\n",
       "        (x_upd): Upsample()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Upsample()\n",
       "        (x_upd): Upsample()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Upsample()\n",
       "        (x_upd): Upsample()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (10-11): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(128, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93563910, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "total_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34119683, (127683593, 24576))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = 256\n",
    "in_channels = 3\n",
    "model_channels = 128\n",
    "out_channels = 3\n",
    "\n",
    "model_L = FineTuningDiffusionModel(image_size, in_channels, model_channels, out_channels, pt_model = lora_model)\n",
    "\n",
    "\n",
    "#total_parameters(model)\n",
    "model_L\n",
    "total_parameters(model_L)[0] - total_parameters(model)[0], total_parameters(model_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 256, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "pht = \"/home/cmk2000/Documents/Years 3/Python codes/Codes/image/69037.png\"\n",
    "x = torch.tensor(cv2.imread(pht,0))/255\n",
    "x = x.unsqueeze(0).unsqueeze(0).repeat(2,3,1,1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-4.4464e-01, -8.0025e-02, -5.8108e-02,  ...,  5.4666e-02,\n",
       "            6.3529e-02,  1.1771e-01],\n",
       "          [ 1.0024e-01, -3.1844e-02, -4.6185e-01,  ...,  6.8132e-01,\n",
       "           -1.0140e+00,  6.5924e-01],\n",
       "          [-1.2030e-01,  1.1550e-02, -2.7586e-01,  ...,  2.7033e-01,\n",
       "           -8.7674e-02,  5.1268e-01],\n",
       "          ...,\n",
       "          [-1.6690e-01, -1.8327e-01, -2.4938e-01,  ..., -7.5878e-02,\n",
       "           -9.3964e-02, -1.1954e-01],\n",
       "          [-5.7894e-01,  7.0161e-02,  6.6814e-02,  ..., -2.1156e-01,\n",
       "           -3.8093e-01,  2.7093e-02],\n",
       "          [ 3.1853e-01,  3.4688e-01,  3.6710e-01,  ...,  3.8196e-01,\n",
       "            5.0094e-01, -8.0849e-02]],\n",
       "\n",
       "         [[ 3.3068e-01,  4.9126e-02,  5.3883e-02,  ..., -1.7130e-01,\n",
       "            1.9943e-01,  8.8986e-01],\n",
       "          [ 3.5806e-01,  2.1796e-01,  4.4262e-01,  ...,  9.1358e-01,\n",
       "            2.7440e-01,  4.1025e-01],\n",
       "          [ 1.3305e-01,  3.6046e-01,  9.5942e-02,  ..., -8.2276e-02,\n",
       "            3.7286e-01,  4.4076e-01],\n",
       "          ...,\n",
       "          [ 1.7361e-02,  5.5115e-03,  3.0780e-01,  ...,  1.0288e-01,\n",
       "            7.9957e-01,  3.5445e-01],\n",
       "          [ 1.2184e-02,  1.2475e-02,  1.3289e-01,  ...,  5.8525e-01,\n",
       "            6.5049e-01,  3.9776e-01],\n",
       "          [ 6.8106e-01,  1.1648e-01,  3.5744e-01,  ...,  4.6276e-01,\n",
       "            5.2900e-01,  9.7822e-02]],\n",
       "\n",
       "         [[ 7.4397e-01,  1.8096e-01,  1.5679e-01,  ...,  4.9877e-02,\n",
       "            1.2373e-03, -2.9846e-01],\n",
       "          [ 2.9516e-01, -1.6826e-01,  2.5353e-01,  ...,  4.4353e-01,\n",
       "           -1.0050e+00,  3.3377e-02],\n",
       "          [ 3.0945e-01,  3.4729e-01,  2.0067e-01,  ...,  3.0511e-01,\n",
       "           -1.6458e-01, -2.9383e-02],\n",
       "          ...,\n",
       "          [ 1.8979e-01,  1.0821e-01,  3.6501e-01,  ...,  1.0416e-01,\n",
       "            2.5211e-02,  1.3736e-01],\n",
       "          [ 6.5134e-01, -1.7282e-01, -2.8104e-01,  ...,  2.7479e-01,\n",
       "           -3.0920e-01,  7.3745e-02],\n",
       "          [-3.5537e-01, -2.1075e-01, -3.4771e-01,  ...,  2.5290e-01,\n",
       "            2.6934e-01,  2.7687e-01]],\n",
       "\n",
       "         [[-8.2513e-01, -1.2727e+00, -1.5066e+00,  ..., -1.0364e+00,\n",
       "           -9.6253e-01, -6.5594e-01],\n",
       "          [-1.2567e+00, -2.0145e+00, -2.4352e+00,  ..., -1.4032e+00,\n",
       "           -1.2598e+00, -9.4004e-01],\n",
       "          [-1.4688e+00, -2.4115e+00, -3.0170e+00,  ..., -1.5546e+00,\n",
       "           -1.3868e+00, -9.9121e-01],\n",
       "          ...,\n",
       "          [-1.6775e+00, -2.7322e+00, -3.4444e+00,  ..., -3.0502e+00,\n",
       "           -2.4614e+00, -1.5834e+00],\n",
       "          [-1.4710e+00, -2.4050e+00, -2.9719e+00,  ..., -2.3828e+00,\n",
       "           -2.0679e+00, -1.3830e+00],\n",
       "          [-9.0963e-01, -1.5152e+00, -1.8526e+00,  ..., -1.3618e+00,\n",
       "           -1.2810e+00, -9.0050e-01]],\n",
       "\n",
       "         [[-1.1653e+00, -1.7919e+00, -2.0595e+00,  ..., -1.3481e+00,\n",
       "           -1.2442e+00, -8.0461e-01],\n",
       "          [-1.7515e+00, -2.7591e+00, -3.2749e+00,  ..., -1.7957e+00,\n",
       "           -1.6185e+00, -1.1111e+00],\n",
       "          [-1.9498e+00, -3.1242e+00, -3.8364e+00,  ..., -1.9325e+00,\n",
       "           -1.6927e+00, -1.0886e+00],\n",
       "          ...,\n",
       "          [-2.3210e+00, -3.6846e+00, -4.5084e+00,  ..., -3.1927e+00,\n",
       "           -2.6475e+00, -1.6854e+00],\n",
       "          [-1.9805e+00, -3.1323e+00, -3.7527e+00,  ..., -2.5630e+00,\n",
       "           -2.2463e+00, -1.4795e+00],\n",
       "          [-1.2189e+00, -1.8930e+00, -2.2640e+00,  ..., -1.4675e+00,\n",
       "           -1.3721e+00, -9.3774e-01]],\n",
       "\n",
       "         [[-9.5276e-01, -1.4238e+00, -1.6019e+00,  ..., -1.1954e+00,\n",
       "           -1.1530e+00, -7.4096e-01],\n",
       "          [-1.4923e+00, -2.3288e+00, -2.7020e+00,  ..., -1.6995e+00,\n",
       "           -1.6747e+00, -1.1412e+00],\n",
       "          [-1.7160e+00, -2.7431e+00, -3.3201e+00,  ..., -2.0863e+00,\n",
       "           -1.8681e+00, -1.1960e+00],\n",
       "          ...,\n",
       "          [-1.8729e+00, -2.9775e+00, -3.5751e+00,  ..., -3.2222e+00,\n",
       "           -2.7075e+00, -1.6929e+00],\n",
       "          [-1.5626e+00, -2.4254e+00, -2.8425e+00,  ..., -2.6180e+00,\n",
       "           -2.2881e+00, -1.4592e+00],\n",
       "          [-9.4925e-01, -1.4495e+00, -1.6762e+00,  ..., -1.5350e+00,\n",
       "           -1.4054e+00, -9.4532e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.4464e-01, -8.0025e-02, -5.8108e-02,  ...,  5.4666e-02,\n",
       "            6.3529e-02,  1.1771e-01],\n",
       "          [ 1.0024e-01, -3.1844e-02, -4.6185e-01,  ...,  6.8132e-01,\n",
       "           -1.0140e+00,  6.5924e-01],\n",
       "          [-1.2030e-01,  1.1550e-02, -2.7586e-01,  ...,  2.7033e-01,\n",
       "           -8.7674e-02,  5.1268e-01],\n",
       "          ...,\n",
       "          [-1.6690e-01, -1.8327e-01, -2.4938e-01,  ..., -7.5878e-02,\n",
       "           -9.3964e-02, -1.1954e-01],\n",
       "          [-5.7894e-01,  7.0161e-02,  6.6814e-02,  ..., -2.1156e-01,\n",
       "           -3.8093e-01,  2.7093e-02],\n",
       "          [ 3.1853e-01,  3.4688e-01,  3.6710e-01,  ...,  3.8196e-01,\n",
       "            5.0094e-01, -8.0849e-02]],\n",
       "\n",
       "         [[ 3.3068e-01,  4.9126e-02,  5.3883e-02,  ..., -1.7130e-01,\n",
       "            1.9943e-01,  8.8986e-01],\n",
       "          [ 3.5806e-01,  2.1796e-01,  4.4262e-01,  ...,  9.1358e-01,\n",
       "            2.7440e-01,  4.1025e-01],\n",
       "          [ 1.3305e-01,  3.6046e-01,  9.5942e-02,  ..., -8.2276e-02,\n",
       "            3.7286e-01,  4.4076e-01],\n",
       "          ...,\n",
       "          [ 1.7361e-02,  5.5115e-03,  3.0780e-01,  ...,  1.0288e-01,\n",
       "            7.9957e-01,  3.5445e-01],\n",
       "          [ 1.2184e-02,  1.2475e-02,  1.3289e-01,  ...,  5.8525e-01,\n",
       "            6.5049e-01,  3.9776e-01],\n",
       "          [ 6.8106e-01,  1.1648e-01,  3.5744e-01,  ...,  4.6276e-01,\n",
       "            5.2900e-01,  9.7822e-02]],\n",
       "\n",
       "         [[ 7.4397e-01,  1.8096e-01,  1.5679e-01,  ...,  4.9877e-02,\n",
       "            1.2373e-03, -2.9846e-01],\n",
       "          [ 2.9516e-01, -1.6826e-01,  2.5353e-01,  ...,  4.4353e-01,\n",
       "           -1.0050e+00,  3.3377e-02],\n",
       "          [ 3.0945e-01,  3.4729e-01,  2.0067e-01,  ...,  3.0511e-01,\n",
       "           -1.6458e-01, -2.9383e-02],\n",
       "          ...,\n",
       "          [ 1.8979e-01,  1.0821e-01,  3.6501e-01,  ...,  1.0416e-01,\n",
       "            2.5211e-02,  1.3736e-01],\n",
       "          [ 6.5134e-01, -1.7282e-01, -2.8104e-01,  ...,  2.7479e-01,\n",
       "           -3.0920e-01,  7.3745e-02],\n",
       "          [-3.5537e-01, -2.1075e-01, -3.4771e-01,  ...,  2.5290e-01,\n",
       "            2.6934e-01,  2.7687e-01]],\n",
       "\n",
       "         [[-8.2513e-01, -1.2727e+00, -1.5066e+00,  ..., -1.0364e+00,\n",
       "           -9.6253e-01, -6.5594e-01],\n",
       "          [-1.2567e+00, -2.0145e+00, -2.4352e+00,  ..., -1.4032e+00,\n",
       "           -1.2598e+00, -9.4004e-01],\n",
       "          [-1.4688e+00, -2.4115e+00, -3.0170e+00,  ..., -1.5546e+00,\n",
       "           -1.3868e+00, -9.9121e-01],\n",
       "          ...,\n",
       "          [-1.6775e+00, -2.7322e+00, -3.4444e+00,  ..., -3.0502e+00,\n",
       "           -2.4614e+00, -1.5834e+00],\n",
       "          [-1.4710e+00, -2.4050e+00, -2.9719e+00,  ..., -2.3828e+00,\n",
       "           -2.0679e+00, -1.3830e+00],\n",
       "          [-9.0963e-01, -1.5152e+00, -1.8526e+00,  ..., -1.3618e+00,\n",
       "           -1.2810e+00, -9.0050e-01]],\n",
       "\n",
       "         [[-1.1653e+00, -1.7919e+00, -2.0595e+00,  ..., -1.3481e+00,\n",
       "           -1.2442e+00, -8.0461e-01],\n",
       "          [-1.7515e+00, -2.7591e+00, -3.2749e+00,  ..., -1.7957e+00,\n",
       "           -1.6185e+00, -1.1111e+00],\n",
       "          [-1.9498e+00, -3.1242e+00, -3.8364e+00,  ..., -1.9325e+00,\n",
       "           -1.6927e+00, -1.0886e+00],\n",
       "          ...,\n",
       "          [-2.3210e+00, -3.6846e+00, -4.5084e+00,  ..., -3.1927e+00,\n",
       "           -2.6475e+00, -1.6854e+00],\n",
       "          [-1.9805e+00, -3.1323e+00, -3.7527e+00,  ..., -2.5630e+00,\n",
       "           -2.2463e+00, -1.4795e+00],\n",
       "          [-1.2189e+00, -1.8930e+00, -2.2640e+00,  ..., -1.4675e+00,\n",
       "           -1.3721e+00, -9.3774e-01]],\n",
       "\n",
       "         [[-9.5276e-01, -1.4238e+00, -1.6019e+00,  ..., -1.1954e+00,\n",
       "           -1.1530e+00, -7.4096e-01],\n",
       "          [-1.4923e+00, -2.3288e+00, -2.7020e+00,  ..., -1.6995e+00,\n",
       "           -1.6747e+00, -1.1412e+00],\n",
       "          [-1.7160e+00, -2.7431e+00, -3.3201e+00,  ..., -2.0863e+00,\n",
       "           -1.8681e+00, -1.1960e+00],\n",
       "          ...,\n",
       "          [-1.8729e+00, -2.9775e+00, -3.5751e+00,  ..., -3.2222e+00,\n",
       "           -2.7075e+00, -1.6929e+00],\n",
       "          [-1.5626e+00, -2.4254e+00, -2.8425e+00,  ..., -2.6180e+00,\n",
       "           -2.2881e+00, -1.4592e+00],\n",
       "          [-9.4925e-01, -1.4495e+00, -1.6762e+00,  ..., -1.5350e+00,\n",
       "           -1.4054e+00, -9.4532e-01]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_L(x, timesteps=torch.tensor([4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.out(torch.randn(1,128,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pht = \"/home/cmk2000/Documents/Years 3/Python codes/Codes/image/69037.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168612620, 24576)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_parameters(model_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "print() takes at most 4 keyword arguments (15 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     config \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Access the n value\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: print() takes at most 4 keyword arguments (15 given)"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Load the YAML file\n",
    "with open('/home/cmk2000/Documents/Years 3/Python codes/Codes/LLMs/Fine tuning  diffusion models/configs/training_fine_tuning_lora_model.yaml', 'r') as file:\n",
    "    configs = yaml.safe_load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 4 5 6 7\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blobfile as bf\n",
    "from mpi4py import MPI\n",
    "import torch as th\n",
    "import torch.distributed as dist\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CUDA_VISIBLE_DEVICES'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCUDA_VISIBLE_DEVICES\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/horus_env/lib/python3.9/os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    676\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CUDA_VISIBLE_DEVICES'"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdist\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_world_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/horus_env/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:1555\u001b[0m, in \u001b[0;36mget_world_size\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _rank_not_in_group(group):\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_group_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/horus_env/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:836\u001b[0m, in \u001b[0;36m_get_group_size\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a given group's world size.\"\"\"\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group \u001b[38;5;129;01mis\u001b[39;00m GroupMember\u001b[38;5;241m.\u001b[39mWORLD \u001b[38;5;129;01mor\u001b[39;00m group \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 836\u001b[0m     default_pg \u001b[38;5;241m=\u001b[39m \u001b[43m_get_default_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_pg\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m group\u001b[38;5;241m.\u001b[39msize()\n",
      "File \u001b[0;32m~/.conda/envs/horus_env/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:977\u001b[0m, in \u001b[0;36m_get_default_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the default process group created by init_process_group.\"\"\"\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_initialized():\n\u001b[0;32m--> 977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault process group has not been initialized, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    979\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease make sure to call init_process_group.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    980\u001b[0m     )\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GroupMember\u001b[38;5;241m.\u001b[39mWORLD\n",
      "\u001b[0;31mValueError\u001b[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.distributed as dist\n",
    "\n",
    "dist.get_world_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms #type : ignore\n",
    "tra = transforms.Compose([transforms.ToPILImage(), transforms.Resize((256,256)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.util import strtobool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as transforms #type : ignore\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth = \"/home/cmk2000/Documents/Years 3/Python codes/Codes/image/69037.png\"\n",
    "pt = \"/home/cmk2000/Documents/Years 3/Python codes/Codes/image\"\n",
    "\n",
    "x = np.array(Image.open(pth))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m l \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39miglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.png\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "l = glob.iglob(os.path.join(pt, '*.png'))\n",
    "l.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "l[0].rsplit(\"/\", 1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmk2000/.conda/envs/horus_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3) (256, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open(\"/home/cmk2000/Documents/Years 3/Python codes/Codes/image/69037.png\")\n",
    "print(np.array(image).shape, image.size)\n",
    "transform(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(256 // 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class test(nn.Module):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        self.modules = 12\n",
    "    def __call__(self, y):\n",
    "        return self.x + y + self.modules\n",
    "\n",
    "t = test(3)\n",
    "t(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "horus_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
